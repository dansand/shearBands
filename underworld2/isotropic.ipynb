{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear bands\n",
    "\n",
    "This series of notebook explores shear band emergence. The models are based on \n",
    "\n",
    "\n",
    "Spiegelman, Marc, Dave A. May, and Cian R. Wilson. \"On the solvability of incompressible Stokes with viscoplastic rheologies in geodynamics.\" Geochemistry, Geophysics, Geosystems (2016).\n",
    "\n",
    "We first implement the instantaneous model described in that paper, and then look at the at series of extensions\n",
    "\n",
    "* mohr-coloumb criteria as in kaus \n",
    "\n",
    "* transverse isotropic plasticity\n",
    "\n",
    "* elasticity\n",
    "\n",
    "* sticky air vs neumann\n",
    "\n",
    "\n",
    "* time dependence, hardening/softening\n",
    "\n",
    "questions:\n",
    "\n",
    "* how do we get the plastic part of the strain\n",
    "* can we control the solver - i.e do the Picard iterations manually\n",
    "* how should we do the pressure split for long term models?\n",
    "    * track the surface and integrate down, or do a 'static solve'\n",
    "    \n",
    "    \n",
    "    \n",
    "## Scaling\n",
    "\n",
    "Of course, the magnitude of the nonlinear residual will depend on how the problem is scaled and we find that it is useful to scale variables such that they are roughly O(1) when solving. For this problem, we scale velocities by U0, viscosities by g051022 Pa s, and stresses/pressures by g0U0=H where H \n",
    "\n",
    "### NOTES\n",
    "\n",
    "   1) This notebook also introduces Lagrangian integration with higher order elements. In this case it is necessary to  manually introduce the swarm population manager and explicitly call for the re-population of the elements after the particles have been advected.\n",
    "   \n",
    "   2) The mesh is deformed to follow the moving boundaries. This is an ALE problem in which the material history attached to the particles and the boundary-deformation history is attached to the mesh. \n",
    "   \n",
    "   3) There is no thermal component to this notebook and hence no ALE correction for the moving mesh applies to the advection term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "#Stubborn version number conflicts - For now...\n",
    "#####\n",
    "try:\n",
    "    natsort.natsort = natsort.natsorted\n",
    "except:\n",
    "    natsort.natsort = natsort.natsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#In case NN swarm interpolation is required\n",
    "\n",
    "from scipy.spatial import cKDTree as kdTree\n",
    "\n",
    "def nn_evaluation(fromSwarm, toSwarm, n=1, weighted=False):\n",
    "    \"\"\"\n",
    "    This function provides nearest neighbour information for uw swarms, \n",
    "    given the \"toSwarm\", this function returns the indices of the n nearest neighbours in \"fromSwarm\"\n",
    "    it also returns the inverse-distance if weighted=True. \n",
    "    \n",
    "    The function works in parallel.\n",
    "    \n",
    "    The arrays come out a bit differently when used in nearest neighbour form\n",
    "    (n = 1), or IDW: (n > 1). The examples belowe show how to fill out a swarm variable in each case. \n",
    "    \n",
    "    \n",
    "    Usage n == 1:\n",
    "    ------------\n",
    "    ix, weights = nn_evaluation(swarm, data, n=1, weighted=False)\n",
    "    toSwarmVar.data[:][:,0] = np.average(fromSwarmVar[ix][:,0], weights=weights)\n",
    "    \n",
    "    Usage n > 1:\n",
    "    ------------\n",
    "    ix, weights = nn_evaluation(swarm, data, n=2, weighted=False)\n",
    "    toSwarmVar.data[:][:,0] =  np.average(fromSwarmVar[ix][:,:,0], weights=weights, axis=1)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if len(toSwarm) > 0: #this is required for safety in parallel\n",
    "        \n",
    "        #this should avoid building the tree again when this function is called multiple times.\n",
    "        try:\n",
    "            tree = fromSwarm.tree\n",
    "            #print(1)\n",
    "        except:\n",
    "            #print(2)\n",
    "            fromSwarm.tree = kdTree(fromSwarm.particleCoordinates.data)\n",
    "            tree = fromSwarm.tree\n",
    "        d, ix = tree.query(toSwarm, n)\n",
    "        if n == 1:\n",
    "            weights = np.ones(toSwarm.shape[0])\n",
    "        elif not weighted:\n",
    "            weights = np.ones((toSwarm.shape[0], n))*(1./n)\n",
    "        else:\n",
    "            weights = (1./d[:])/(1./d[:]).sum(axis=1)[:,None]\n",
    "        return ix,  weights \n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model letter and number\n",
    "############\n",
    "\n",
    "\n",
    "#Model letter identifier default\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier default:\n",
    "ModNum = 0\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameter dictionaries\n",
    "\n",
    "* Parameters are stored in dictionaries. \n",
    "* If starting from checkpoint, parameters are loaded using pickle\n",
    "* If params are passed in as flags to the script, they overwrite \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Parameter / settings dictionaries get saved&loaded using pickle\n",
    "###########\n",
    " \n",
    "dp = edict({}) #dimensional parameters\n",
    "sf = edict({}) #scaling factors\n",
    "ndp = edict({}) #dimensionless paramters\n",
    "md = edict({}) #model paramters, flags etc\n",
    "#od = edict({}) #output frequencies\n",
    " \n",
    "\n",
    "\n",
    "dict_list = [dp, sf, ndp, md]\n",
    "dict_names = ['dp.pkl', 'sf.pkl', 'ndp.pkl', 'md.pkl']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical parameters, scale factors and dimensionless pramters in easyDicts\n",
    "#dp : dimensional paramters\n",
    "###########\n",
    "\n",
    "\n",
    "dp = edict({'LS':10*1e3, #Scaling Length scale\n",
    "            #'asthenosphere': (30*1e3)/4, #level from bottom of model, set to zero for Kaus' model setup\n",
    "            'asthenosphere': (0.*1e3)/4, #level from bottom of model, set to zero for Kaus' model setup\n",
    "            'eta0':1e22,\n",
    "            'eta1':1e25,\n",
    "            'eta2':1e20,\n",
    "            #'U0':0.0125/(3600*24*365),  #m/s speigelman et al\n",
    "            'U0':0.006/(3600*24*365),  #m/s kaus\n",
    "            'rho': 2700., #kg/m3\n",
    "            'g':9.81,\n",
    "            'cohesion':40e6,  \n",
    "            'fa':25.        #friction angle degrees\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modelling and Physics switches\n",
    "#md : model dictionary\n",
    "\n",
    "md = edict({'refineMesh':False,\n",
    "            'stickyAir':False,\n",
    "            'aspectRatio':4.,\n",
    "            'res':64,\n",
    "            'ppc':25,\n",
    "            'tol':1e-3,\n",
    "            'maxIts':150,\n",
    "            'notch_fac':1.\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If command line args are given, overwrite\n",
    "#Note that this assumes that params as commans line args/\n",
    "#only append to the 'dimensional' and 'model' dictionary (not the non-dimensional)\n",
    "###########    \n",
    "\n",
    "\n",
    "###########\n",
    "#If extra arguments are provided to the script\" eg:\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3=3.0\n",
    "###\n",
    "###This would assign ModNum = 2, all other values go into the dp dictionary, under key names provided\n",
    "###\n",
    "###Two operators are searched for, = & *=\n",
    "###\n",
    "###If =, parameter is re-assigned to givn value\n",
    "###If *=, parameter is multipled by given value\n",
    "###\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3*=3.0\n",
    "###########\n",
    "\n",
    "for farg in sys.argv[1:]:\n",
    "    try:\n",
    "        (dicitem,val) = farg.split(\"=\") #Split on equals operator\n",
    "        (dic,arg) = dicitem.split(\".\") #colon notation\n",
    "        if '*=' in farg:\n",
    "            (dicitem,val) = farg.split(\"*=\") #If in-place multiplication, split on '*='\n",
    "            (dic,arg) = dicitem.split(\".\")\n",
    "            \n",
    "        if val == 'True': \n",
    "            val = True\n",
    "        elif val == 'False':     #First check if args are boolean\n",
    "            val = False\n",
    "        else:\n",
    "            try:\n",
    "                val = float(val) #next try to convert  to a float,\n",
    "            except ValueError:\n",
    "                pass             #otherwise leave as string\n",
    "        #Update the dictionary\n",
    "        if farg.startswith('dp'):\n",
    "            if '*=' in farg:\n",
    "                dp[arg] = dp[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                dp[arg] = val    #or reassign parameter by given value\n",
    "        if farg.startswith('md'):\n",
    "            if '*=' in farg:\n",
    "                md[arg] = md[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                md[arg] = val    #or reassign parameter by given value\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "comm.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000.0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.LS**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only build these guys first time around, otherwise the read from checkpoints\n",
    "#Important because some of these params (like SZ location) may change during model evolution\n",
    "\n",
    "\n",
    "#sf : scaling factors\n",
    "#ndp : non dimensional paramters\n",
    "\n",
    "\n",
    "\n",
    "sf = edict({'stress':(dp.eta0*dp.U0)/dp.LS,\n",
    "            'vel':dp.U0,\n",
    "            'density':dp.LS**3,\n",
    "            'g':dp.g,\n",
    "            'rho':(dp.eta0*dp.U0)/(dp.LS**2*dp.g)\n",
    "           })\n",
    "\n",
    "#dimensionless parameters\n",
    "\n",
    "ndp = edict({'U':dp.U0/sf.vel,\n",
    "             'asthenosphere':dp.asthenosphere/dp.LS,\n",
    "             'eta1':dp.eta1/dp.eta0,\n",
    "             'eta2':dp.eta2/dp.eta0,\n",
    "             'cohesion':dp.cohesion/sf.stress,\n",
    "             'fa':math.tan((math.pi/180.)*dp.fa), #convert friction angle to coefficient,\n",
    "             'g': dp.g/sf.g,\n",
    "             'rho':dp.rho/sf.rho\n",
    "            \n",
    "            }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------\n",
    "\n",
    "Note: the use of a pressure-sensitive rheology suggests that it is important to use a Q2/dQ1 element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minX  = -2.0\n",
    "maxX  =  2.0\n",
    "maxY  = 1.0\n",
    "meshV =  1.0\n",
    "\n",
    "if md.stickyAir:\n",
    "    maxY  = 1.1\n",
    "\n",
    "\n",
    "resY = int(md.res)\n",
    "resX = int(resY*md.aspectRatio)\n",
    "\n",
    "elementType=\"Q2/dPc1\"  # This is enough for a test but not to use the code in anger\n",
    "\n",
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (elementType), \n",
    "                                 elementRes  = ( resX, resY), \n",
    "                                 minCoord    = ( minX, 0.), \n",
    "                                 maxCoord    = ( maxX, maxY),\n",
    "                                 periodic    = [False, False]  ) \n",
    "\n",
    "\n",
    "\n",
    "velocityField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=mesh.dim )\n",
    "pressureField    = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions\n",
    "\n",
    "Pure shear with moving  walls â€” all boundaries are zero traction with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "base   = mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "top    = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "\n",
    "allWalls = iWalls + jWalls\n",
    "\n",
    "velocityBCs = uw.conditions.DirichletCondition( variable        = velocityField, \n",
    "                                                indexSetsPerDof = (iWalls, base) )\n",
    "\n",
    "for index in mesh.specialSets[\"MinI_VertexSet\"]:\n",
    "    velocityField.data[index] = [meshV, 0.]\n",
    "for index in mesh.specialSets[\"MaxI_VertexSet\"]:\n",
    "    velocityField.data[index] = [ -meshV, 0.]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the material swarm and passive tracers\n",
    "\n",
    "The material swarm is used for tracking deformation and history dependence of the rheology\n",
    "\n",
    "Passive swarms can track all sorts of things but lack all the machinery for integration and re-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swarm  = uw.swarm.Swarm( mesh=mesh )\n",
    "swarmLayout = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=swarm, particlesPerCell=int(md.ppc) )\n",
    "swarm.populate_using_layout( layout=swarmLayout )\n",
    "\n",
    "# create pop control object\n",
    "pop_control = uw.swarm.PopulationControl(swarm)\n",
    "\n",
    "surfaceSwarm = uw.swarm.Swarm( mesh=mesh )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a particle advection system\n",
    "\n",
    "Note that we need to set up one advector systems for each particle swarm (our global swarm and a separate one if we add passive tracers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advector        = uw.systems.SwarmAdvector( swarm=swarm,            velocityField=velocityField, order=2 )\n",
    "advector2       = uw.systems.SwarmAdvector( swarm=surfaceSwarm,     velocityField=velocityField, order=2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add swarm variables\n",
    "\n",
    "We are using a single material with a single rheology. We need to track the plastic strain in order to have some manner of strain-related softening (e.g. of the cohesion or the friction coefficient). For visualisation of swarm data we need an actual swarm variable and not just the computation.\n",
    "\n",
    "Other variables are used to track deformation in the shear band etc.\n",
    "\n",
    "**NOTE**:  Underworld needs all the swarm variables defined before they are initialised or there will be / can be memory problems (at least it complains about them !). That means we need to add the monitoring variables now, even if we don't always need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tracking different materials\n",
    "\n",
    "materialVariable = swarm.add_variable( dataType=\"int\", count=1 )\n",
    "\n",
    "\n",
    "# passive markers at the surface\n",
    "\n",
    "surfacePoints = np.zeros((1000,2))\n",
    "surfacePoints[:,0] = np.linspace(minX+0.01, maxX-0.01, 1000)\n",
    "surfacePoints[:,1] = 1.0 #\n",
    "\n",
    "surfaceSwarm.add_particles_with_coordinates( surfacePoints )\n",
    "yvelsurfVar = surfaceSwarm.add_variable( dataType=\"double\", count=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise swarm variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yvelsurfVar.data[...] = (0.)\n",
    "materialVariable.data[...] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material distribution in the domain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise the 'materialVariable' data to represent different materials. \n",
    "material1 = 1 # viscoplastic\n",
    "material0 = 0 # accommodation layer a.k.a. Sticky Air\n",
    "material2 = 2 # Under layer \n",
    "\n",
    "\n",
    "materialVariable.data[:] = 0.\n",
    "\n",
    "# The particle coordinates will be the input to the function evaluate (see final line in this cell).\n",
    "# We get proxy for this now using the input() function.\n",
    "\n",
    "coord = fn.input()\n",
    "\n",
    "# Setup the conditions list for the following conditional function. Where the\n",
    "# z coordinate (coordinate[1]) is less than the perturbation, set to lightIndex.\n",
    "\n",
    "\n",
    "\n",
    "notchWidth = (1./32.) * md.notch_fac\n",
    "\n",
    "notchCond = operator.and_(coord[1] < ndp.asthenosphere + notchWidth, operator.and_(coord[0] < notchWidth, coord[0] > -1.*notchWidth )  )\n",
    "\n",
    "mu = notchWidth\n",
    "sig = 1/48.\n",
    "gausFn1 = 1/16.*fn.math.exp(-1.*(coord[0] - mu)**2/(2 * sig**2)) + ndp.asthenosphere\n",
    "mu = -1.*notchWidth\n",
    "gausFn2 = 1/16.*fn.math.exp(-1.*(coord[0] - mu)**2/(2 * sig**2)) + ndp.asthenosphere\n",
    "\n",
    "conditions = [ (       coord[1] > 1.0 , material0 ), #air\n",
    "               (       coord[1] < ndp.asthenosphere , material2 ), #asthenosphere\n",
    "               (       coord[1] < gausFn1 , material2 ), #asthenosphere\n",
    "               (       coord[1] < gausFn2 , material2 ), #asthenosphere       \n",
    "\n",
    "               (       notchCond , material2 ),\n",
    "               (       True ,           material1 ) ]  #visco-plastic\n",
    "\n",
    "# The actual function evaluation. Here the conditional function is evaluated at the location\n",
    "# of each swarm particle. The results are then written to the materialVariable swarm variable.\n",
    "\n",
    "materialVariable.data[:] = fn.branching.conditional( conditions ).evaluate(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figMat = glucifer.Figure( figsize=(1200,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figMat.append( glucifer.objects.Points(swarm,materialVariable, pointSize=2.0) )\n",
    "figMat.append( glucifer.objects.Mesh(mesh))\n",
    "#figMat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rheology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Background viscosity\n",
    "\n",
    "visc0 = 0.01      #if sticky air\n",
    "visc1 = ndp.eta1\n",
    "visc2 = ndp.eta2\n",
    "\n",
    "\n",
    "viscosityMap = { material0: visc0, material1:visc1, material2:visc2 }\n",
    "\n",
    "backgroundViscosityFn  = fn.branching.map( fn_key = materialVariable, \n",
    "                                           mapping = viscosityMap )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a yield criterion (function)\n",
    "\n",
    "\\begin{equation}\n",
    "    \\tau_\\textrm{yield} = C(\\varepsilon_p) + \\mu p \n",
    "\\end{equation}\n",
    "\n",
    "The yield strength described above needs to be evaluated on the fly at the particles (integration points). It therefore needs to be a function composed of mesh variables, swarm variables, constants, and mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Friction - in this form it could also be made to weaken with strain\n",
    "\n",
    "\n",
    "cohesion0       = fn.misc.constant(ndp.cohesion)\n",
    "cohesionFn = cohesion0\n",
    "\n",
    "# Drucker-Prager yield criterion\n",
    "\n",
    "\n",
    "yieldStressFn   = cohesionFn + ndp.fa * pressureField  \n",
    "\n",
    "yieldStressFn   = cohesionFn + ndp.fa * fn.misc.max(fn.misc.constant(0.), pressureField) #in this case only positive pressures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effective viscosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first define strain rate tensor\n",
    "\n",
    "strainRateFn = fn.tensor.symmetric( velocityField.fn_gradient )\n",
    "strainRate_2ndInvariantFn = fn.tensor.second_invariant(strainRateFn)\n",
    "\n",
    "# now compute a viscosity assuming yielding\n",
    "\n",
    "min_viscosity = visc0  # same as the air ... \n",
    "\n",
    "yieldingViscosityFn =  0.5 * yieldStressFn / (strainRate_2ndInvariantFn+1.0e-18)\n",
    "\n",
    "#viscosityFn = fn.exception.SafeMaths( fn.misc.max(fn.misc.min(yieldingViscosityFn, \n",
    "#                                                              backgroundViscosityFn), \n",
    "#                                                  min_viscosity))\n",
    "\n",
    "\n",
    "viscosityFn = fn.exception.SafeMaths( fn.misc.max(\n",
    "                                              1./((1./yieldingViscosityFn) + (1./backgroundViscosityFn))\n",
    "                                             , min_viscosity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buoyancy forces\n",
    "\n",
    "In this example, no buoyancy forces are considered. However, to establish an appropriate pressure gradient in the material, it would normally be useful to map density from material properties and create a buoyancy force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densityMap = { material0: 0.0, material1:ndp.rho, material2:ndp.rho }\n",
    "\n",
    "densityFn = fn.branching.map( fn_key=materialVariable, mapping=densityMap )\n",
    "\n",
    "# And the final buoyancy force function.\n",
    "z_hat = ( 0.0, 1.0 )\n",
    "buoyancyFn = -densityFn * z_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System setup\n",
    "-----\n",
    "\n",
    "Setup a Stokes equation system and connect a solver up to it.  \n",
    "\n",
    "In this example, no buoyancy forces are considered. However, to establish an appropriate pressure gradient in the material, it would normally be useful to map density from material properties and create a buoyancy force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokes = uw.systems.Stokes(    velocityField = velocityField, \n",
    "                               pressureField = pressureField,\n",
    "                               conditions    = velocityBCs,\n",
    "                               fn_viscosity  = viscosityFn, \n",
    "                               fn_bodyforce  = buoyancyFn )\n",
    "\n",
    "solver = uw.systems.Solver( stokes )\n",
    "\n",
    "# \"mumps\" is a good alternative for \"lu\" but  # use \"lu\" direct solve and large penalty (if running in serial)\n",
    "\n",
    "if(uw.nProcs()==1):\n",
    "    solver.set_inner_method(\"lu\")\n",
    "    solver.set_penalty(1.0e6) \n",
    "    solver.options.scr.ksp_rtol = 1.0e-3\n",
    "\n",
    "else:\n",
    "    solver.set_inner_method(\"mumps\")\n",
    "    solver.set_penalty(1.0e7)\n",
    "    solver.options.scr.ksp_type=\"cg\"\n",
    "    solver.options.scr.ksp_rtol = 1.0e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#solver.solve( nonLinearIterate=True, nonLinearMaxIterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#solver._stokesSLE._cself.curResidual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Picard iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lithPressureFn = ndp.rho* (1. - coord[1])\n",
    "\n",
    "dynPressure = pressureField - lithPressureFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prevVelocityField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=mesh.dim )\n",
    "\n",
    "dynPressureField    = uw.mesh.MeshVariable( mesh=mesh.subMesh,         nodeDofCount=1)\n",
    "prevdynPressureField    = uw.mesh.MeshVariable( mesh=mesh.subMesh,         nodeDofCount=1)\n",
    "\n",
    "\n",
    "prevVelocityField.data[:] = (0., 0.)\n",
    "dynPressureField.data[:] = 0.\n",
    "prevdynPressureField.data[:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def volumeint(Fn = 1., rFn=1.):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dynPressureField.data[:] = pressureField.data[:] - lithPressureFn.evaluate(mesh.subMesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.99947239618820516, 1.0010495651816242, 1.0010495609186476)\n",
      "1\n",
      "(1.4711887252835527, 1.3993222290633887, 1.3993225926724877)\n",
      "2\n",
      "(0.14328634393503162, 1.450891526987768, 1.4508695185737852)\n",
      "3\n",
      "(0.047298490511923842, 1.2786527554881599, 1.2785487443935166)\n",
      "4\n",
      "(0.030723589254149114, 1.1900707254129441, 1.1895969516377713)\n",
      "5\n",
      "(0.026810067098648891, 1.1130425653809359, 1.1110276077438492)\n",
      "6\n",
      "(0.025160064394936624, 1.0048533995714208, 0.99745069392986807)\n",
      "7\n",
      "(0.022894066571953087, 0.83389131593896271, 0.81338682391532857)\n",
      "8\n",
      "(0.01964974765573153, 0.60314308631074942, 0.5666751676671119)\n",
      "9\n",
      "(0.017382864775248794, 0.37159269503971476, 0.33224010173965562)\n",
      "10\n",
      "(0.016314419392634855, 0.20058040298786275, 0.17196898271265001)\n",
      "11\n",
      "(0.015553902093302848, 0.10019839787142309, 0.083873528206279524)\n",
      "12\n",
      "(0.014764002603203211, 0.04900610542074723, 0.041025255793182148)\n",
      "13\n",
      "(0.013974980480375905, 0.024960301211391388, 0.021834985539987049)\n",
      "14\n",
      "(0.0132697832302214, 0.014342643868248283, 0.013976317254200905)\n",
      "15\n",
      "(0.012674838619194616, 0.0098370912415955483, 0.010932863689395679)\n",
      "16\n",
      "(0.012180439615727241, 0.0078264090438640282, 0.0096295448118656306)\n",
      "17\n",
      "(0.011765647732439237, 0.0067506994234164197, 0.0089191562752313214)\n",
      "18\n",
      "(0.011410297830934885, 0.0060737384197682917, 0.0084523302585418313)\n",
      "19\n",
      "(0.011095215663290121, 0.0056018628175191817, 0.0081079902648010984)\n",
      "20\n",
      "(0.01080492055022627, 0.0052568492785262386, 0.0078352996225275421)\n",
      "21\n",
      "(0.010527885747467811, 0.0049980186410385589, 0.0076068712269042483)\n",
      "22\n",
      "(0.010255734832555721, 0.0048002364592983895, 0.0074056908535513576)\n",
      "23\n",
      "(0.0099826354454250962, 0.0046461855305814041, 0.0072204202195668889)\n",
      "24\n",
      "(0.0097047932461150066, 0.0045255984749995254, 0.0070442428058492606)\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#The underworld Picard interation applies the following residual (SystemLinearEquations.c)\n",
    "\n",
    "#/* Calculate Residual */\n",
    "#      VecAXPY( previousVector, -1.0, currentVector );\n",
    "#      VecNorm( previousVector, NORM_2, &prevVecNorm );\n",
    "#      VecNorm( currentVector, NORM_2, &currVecNorm );\n",
    "#      residual = ((double)prevVecNorm) / ((double)currVecNorm);\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "res1Vals = []\n",
    "res2Vals = []\n",
    "res3Vals = []\n",
    "\n",
    "for i in range(int(md.maxIts)):\n",
    "    \n",
    "    prevVelocityField.data[:] = velocityField.data.copy()\n",
    "    prevdynPressureField.data[:] = dynPressureField.data[:] \n",
    "\n",
    "    \n",
    "    solver.solve( nonLinearIterate=False)\n",
    "    \n",
    "    #Update the dynamic pressure variable\n",
    "    dynPressureField.data[:] = pressureField.data[:] - lithPressureFn.evaluate(mesh.subMesh)\n",
    "    \n",
    "    \n",
    "    ####\n",
    "    #Caluclate a range of norms to assess convergence\n",
    "    ####\n",
    "    \n",
    "    #L2 norm of current velocity\n",
    "    v2 = fn.math.dot(velocityField,  velocityField)\n",
    "    _Vr = volumeint(v2)\n",
    "    velL2 = np.sqrt(_Vr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of delta velocity\n",
    "    \n",
    "    delV = velocityField - prevVelocityField\n",
    "    v2 = fn.math.dot(delV,  delV)\n",
    "    _Vr = volumeint(v2)\n",
    "    delvelL2 = np.sqrt(_Vr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of current dynamic pressure\n",
    "    p2 = fn.math.dot(dynPressureField, dynPressureField)\n",
    "    _Pr = volumeint(p2)\n",
    "    pL2 = np.sqrt(_Pr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of delta dynamic pressure\n",
    "    delP = dynPressureField - prevdynPressureField\n",
    "    p2 = fn.math.dot(delP,  delP)\n",
    "    _Pr = volumeint(p2)\n",
    "    delpL2 = np.sqrt(_Pr.evaluate()[0])\n",
    "    \n",
    "    #Full norm of the primal variables\n",
    "    \n",
    "    x2 = fn.math.dot(velocityField,  velocityField) + fn.math.dot(dynPressureField, dynPressureField)\n",
    "    _Xr = volumeint(x2)\n",
    "    xL2 = np.sqrt(_Xr.evaluate()[0])\n",
    "    \n",
    "    #Full norm of the change in primal variables\n",
    "    \n",
    "    delV = velocityField - prevVelocityField\n",
    "    delP = dynPressureField - prevdynPressureField\n",
    "    x2 = fn.math.dot(delV,  delV) + fn.math.dot(delP, delP)\n",
    "    _Xr = volumeint(x2)\n",
    "    delxL2 = np.sqrt(_Xr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    res1 = abs(delvelL2 /velL2)\n",
    "    res1Vals .append(res1)\n",
    "    \n",
    "    res2 = abs(delpL2 /pL2)\n",
    "    res2Vals .append(res2)\n",
    "    \n",
    "    res3 = abs(delxL2 /xL2)\n",
    "    res3Vals .append(res3)\n",
    "\n",
    "    \n",
    "    count +=1\n",
    "    print(res1, res2, res3)\n",
    "    print(count)\n",
    "    \n",
    "    \n",
    "    #Converged stopping condition\n",
    "    if res1 < md.tol:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#solver._stokesSLE._cself.curResidual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(range(len(resVals)), resVals)\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_ylim(0.0005, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#((20e3*1e-15)*3600*365*24)*100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surfaceArea = uw.utils.Integral(fn=1.0,mesh=mesh, integrationType='surface', surfaceIndexSet=top)\n",
    "surfacePressureIntegral = uw.utils.Integral(fn=pressureField, mesh=mesh, integrationType='surface', surfaceIndexSet=top)\n",
    "\n",
    "(area,) = surfaceArea.evaluate()\n",
    "(p0,) = surfacePressureIntegral.evaluate() \n",
    "\n",
    "pressureField.data[:] -= p0 / area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figSinv = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figSinv .append( glucifer.objects.VectorArrows(mesh, velocityField, arrowHead=0.25, scaling=.075, resolutionI=32, resolutionJ=8) )\n",
    "\n",
    "figSinv .append( glucifer.objects.Points(swarm,strainRate_2ndInvariantFn, pointSize=2.0, valueRange=[1e-3, 5.]) )\n",
    "#figSinv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figVisc = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "\n",
    "figVisc.append( glucifer.objects.Points(swarm, viscosityFn, pointSize=2.0, logScale=True,valueRange=[0.01, 10] ) )\n",
    "#figVisc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscosityFn.evaluate([0.5, 0.5])\n",
    "#velocityField.evaluate([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figPres= glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "#figPres.append( glucifer.objects.Surface(mesh, dynPressure, valueRange=[-1.,2.5] ))\n",
    "figPres.append( glucifer.objects.Points(swarm, dynPressure,pointSize=2.0, valueRange=[-1.,2.5] ))\n",
    "\n",
    "#figPres.draw.label(r'$\\sin (x)$', (0.2,0.7,0))\n",
    "#figPres.append( glucifer.objects.Mesh(mesh,opacity=0.2))\n",
    "\n",
    "#figPres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/T/0/images/figPres.png'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figSinv.save_image(imagePath + \"figSinv.png\")\n",
    "\n",
    "figVisc.save_image(imagePath +  \"figVisc.png\")\n",
    "\n",
    "figPres.save_image(imagePath + \"figPres.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.utils._utils.SavedFileData at 0x7fd7f967b210>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocityField.save(filePath + \"vel.h5\")\n",
    "pressureField.save(filePath + \"pressure.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.utils._utils.SavedFileData at 0x7fd7f968c250>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvelsurfVar.data[...] = velocityField[1].evaluate(surfaceSwarm)\n",
    "yvelsurfVar.save(filePath + \"yvelsurf.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save points to determine shear band angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eii_mean = uw.utils.Integral(strainRate_2ndInvariantFn,mesh).evaluate()[0]/4.\n",
    "\n",
    "eii_std = uw.utils.Integral(fn.math.sqrt(0.25*(strainRate_2ndInvariantFn - eii_mean)**2.), mesh).evaluate()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab all of material points that are above 2 sigma of mean strain rate invariant\n",
    "\n",
    "\n",
    "\n",
    "xv, yv = np.meshgrid(\n",
    "        np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0]), \n",
    "        np.linspace(mesh.minCoord[1], mesh.maxCoord[1], mesh.elementRes[1]))\n",
    "\n",
    "meshGlobs = np.row_stack((xv.flatten(), yv.flatten())).T\n",
    "\n",
    "\n",
    "#Calculate the 2-sigma value of the strain rate invariant function (\n",
    "#we use this a definition for a shear band)\n",
    "eII_2sig = eii_mean  + 2.*eii_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shearbandswarm  = uw.swarm.Swarm( mesh=mesh, particleEscape=True )\n",
    "shearbandswarmlayout  = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=shearbandswarm , particlesPerCell=int(md.ppc/16.) )\n",
    "shearbandswarm.populate_using_layout( layout=shearbandswarmlayout )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shearbandswarm.particleGlobalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True], dtype=bool)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strainRate_2ndInvariantFn.evaluate(shearbandswarm) < eII_2sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where(strainRate_2ndInvariantFn.evaluate(shearbandswarm) < eII_2sig)\n",
    "    shearbandswarm.particleCoordinates.data[mask[0]]= (1e20, 1e20)\n",
    "\n",
    "shearbandswarm.update_particle_owners()    \n",
    "\n",
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where((shearbandswarm.particleCoordinates.data[:,1] < ndp.asthenosphere + notchWidth) | \n",
    "                    (shearbandswarm.particleCoordinates.data[:,1] >  1. - notchWidth) )\n",
    "    shearbandswarm.particleCoordinates.data[mask]= (1e20, 1e20)\n",
    "\n",
    "shearbandswarm.update_particle_owners()\n",
    "\n",
    "\n",
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where(shearbandswarm.particleCoordinates.data[:,0] > -2.*notchWidth)\n",
    "    shearbandswarm.particleCoordinates.data[mask]= (1e20, 1e20)\n",
    "                    \n",
    "shearbandswarm.update_particle_owners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figTest = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figTest.append( glucifer.objects.Points(shearbandswarm, pointSize=2.0, colourBar=False) )\n",
    "\n",
    "#figTest.append( glucifer.objects.Points(swarmCustom , pointSize=4.0,colourBar=False) )\n",
    "\n",
    "\n",
    "figTest .append( glucifer.objects.Surface(mesh,strainRate_2ndInvariantFn, valueRange=[1e-3, 5.]) )\n",
    "#figTest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/T/0/images/figTest.png'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figTest.save_image(imagePath +  \"figTest.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.utils._utils.SavedFileData at 0x7fd7f96cf690>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shearbandswarm.save(filePath + 'swarm.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and save some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll create a function that based on the strain rate 2-sigma value. \n",
    "#Use this to estimate thickness and average pressure within the shear band\n",
    "\n",
    "conds = [ ( (strainRate_2ndInvariantFn >  eII_2sig) & (coord[1] > ndp.asthenosphere + notchWidth), 1.),\n",
    "            (                                           True , 0.) ]\n",
    "\n",
    "\n",
    "conds2 = [ ( (strainRate_2ndInvariantFn <  eII_2sig) & (coord[1] > ndp.asthenosphere + notchWidth), 1.),\n",
    "            (                                           True , 0.) ]\n",
    "\n",
    "\n",
    "# lets also integrate just one eighth of sphere surface\n",
    "_2sigRest= fn.branching.conditional( conds ) \n",
    "\n",
    "_out2sigRest= fn.branching.conditional( conds2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqrtv2 = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "#sqrtv2x = fn.math.sqrt(fn.math.dot(velocityField[0],velocityField[0]))\n",
    "vd = 4.*viscosityFn*strainRate_2ndInvariantFn # there's an extra factor of 2, which is necessary because the of factor of 0.5 in the UW second invariant \n",
    "\n",
    "\n",
    "_rmsint = uw.utils.Integral(sqrtv2, mesh)\n",
    "\n",
    "#_rmsSurf = uw.utils.Integral(sqrtv2x, mesh, integrationType='Surface',surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "\n",
    "_viscMM = fn.view.min_max(viscosityFn)\n",
    "dummyFn = _viscMM.evaluate(swarm)\n",
    "\n",
    "_eiiMM = fn.view.min_max(strainRate_2ndInvariantFn)\n",
    "dummyFn = _eiiMM.evaluate(swarm)\n",
    "\n",
    "#Area and pressure integrals inside / outside shear band\n",
    "_shearArea = uw.utils.Integral(_2sigRest, mesh)\n",
    "_shearPressure = uw.utils.Integral(_2sigRest*dynPressure, mesh)\n",
    "\n",
    "_backgroundArea = uw.utils.Integral(_out2sigRest, mesh)\n",
    "_backgroundPressure = uw.utils.Integral(_out2sigRest*dynPressure, mesh)\n",
    "\n",
    "#dissipation \n",
    "\n",
    "_vdint  = uw.utils.Integral(vd,mesh)\n",
    "_shearVd  = uw.utils.Integral(vd*_2sigRest,mesh)\n",
    "_backgroundVd  = uw.utils.Integral(vd*_out2sigRest,mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_viscMM.min_global(), _viscMM.max_global()\n",
    "#_eiiMM.min_global(), _eiiMM.max_global()\n",
    "\n",
    "rmsint = _rmsint.evaluate()[0]\n",
    "\n",
    "shearArea = _shearArea.evaluate()[0]\n",
    "shearPressure = _shearPressure.evaluate()[0]\n",
    "\n",
    "backgroundArea = _backgroundArea.evaluate()[0]\n",
    "backgroundPressure = _backgroundPressure.evaluate()[0]\n",
    "\n",
    "vdint = _vdint.evaluate()[0]\n",
    "shearVd = _shearVd.evaluate()[0]\n",
    "backgroundVd = _backgroundVd.evaluate()[0]\n",
    "\n",
    "\n",
    "viscmin = _viscMM.min_global()\n",
    "viscmax = _viscMM.max_global()\n",
    "eiimin = _eiiMM.min_global(), \n",
    "eiimax = _eiiMM.max_global()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.511804153638\n"
     ]
    }
   ],
   "source": [
    "fname = filePath + 'swarm.h5'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    with h5py.File(fname,'r') as hf:\n",
    "        #print('List of arrays in this file: \\n', hf.keys())\n",
    "        data = hf.get('data')\n",
    "        np_data = np.array(data)\n",
    "\n",
    "    sbx =  np_data[:,0]\n",
    "    sby =  np_data[:,1]\n",
    "\n",
    "    #sbx =  shearbandswarm.particleCoordinates.data[:,0]\n",
    "    #sby =  shearbandswarm.particleCoordinates.data[:,1]\n",
    "\n",
    "    z = np.polyfit(sbx, sby, 1)\n",
    "    p = np.poly1d(z)\n",
    "    \n",
    "    #newcoords = np.column_stack((sbx, p(sbx)))\n",
    "    angle = math.atan(z[0])*(180./math.pi)\n",
    "    45. - dp.fa\n",
    "    \n",
    "comm.barrier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if rank==0:\n",
    "    dydx = p[1]\n",
    "else:\n",
    "    dydx = 1.\n",
    "\n",
    "# share value of dydx\n",
    "comm.barrier()\n",
    "dydx = comm.bcast(dydx, root = 0)\n",
    "comm.barrier()\n",
    "\n",
    "\n",
    "\n",
    "print(dydx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], dtype=int32)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.linspace(0, -1., 100)\n",
    "newcoords = np.column_stack((xs, dydx*xs ))\n",
    "\n",
    "\n",
    "swarmCustom = uw.swarm.Swarm(mesh)\n",
    "swarmCustom.add_particles_with_coordinates(newcoords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/T/0/images/figTest2.png'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figTest2 = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figTest2.append( glucifer.objects.Points(shearbandswarm, pointSize=2.0, colourBar=False) )\n",
    "\n",
    "figTest2.append( glucifer.objects.Points(swarmCustom , pointSize=4.0,colourBar=False) )\n",
    "\n",
    "\n",
    "figTest2.append( glucifer.objects.Surface(mesh,strainRate_2ndInvariantFn, valueRange=[1e-3, 5.]) )\n",
    "#figTest2.show()\n",
    "\n",
    "figTest2.save_image(imagePath +  \"figTest2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "if uw.rank()==0:\n",
    "\n",
    "    someVals = [rmsint, shearArea ,shearPressure, \n",
    "                backgroundArea, backgroundPressure, viscmin, viscmax, eiimin, eiimax, angle,vdint, shearVd, backgroundVd  ] \n",
    "\n",
    "    with open(os.path.join(outputPath, 'out.csv'), 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow(someVals)\n",
    "        writer.writerow(res1Vals)\n",
    "        writer.writerow(res2Vals)\n",
    "        writer.writerow(res3Vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test = np.array([0.5, 0.5])\n",
    "\n",
    "ys = np.linspace(0, 1, 10)\n",
    "xs = np.zeros(10)\n",
    "\n",
    "points = np.column_stack((xs, ys))\n",
    "\n",
    "\n",
    "ix, weights = nn_evaluation(swarm, points, n=1, weighted=False)\n",
    "ix, weights\n",
    "\n",
    "visc = viscosityFn.evaluate(swarm)[ix]\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "plt.scatter(ys, visc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
